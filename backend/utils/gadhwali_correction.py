import spacy
import stanza
from typing import List, Tuple, Set

# Download the Hindi model (only needs to be run once)
try:
    stanza.download("hi")
except Exception as e:
    print(f"‚ö†Ô∏è Warning: Could not download Stanza model: {e}")

# Initialize models
try:
    nlp = spacy.load("en_core_web_sm")  # For English parsing if needed
    nlp_hi = stanza.Pipeline(lang="hi", processors="tokenize,pos,lemma,depparse")
except Exception as e:
    print(f"‚ö†Ô∏è Warning: Could not load NLP models: {e}")
    nlp = None
    nlp_hi = None

# Custom Gadhwali grammar components
HELPING_VERBS: Set[str] = {"‡§õ‡•Ç", "‡§ö", "‡§π‡•å", "‡§•", "‡§õ‡•à", "‡§õ‡•à‡§®", "‡§õ‡•å‡§Ç", "‡§õ‡•å", "‡§õ‡•å‡§Ç"}
MODALS: Set[str] = {"‡§ö‡•å‡§®", "‡§ö‡§æ‡§π‡•Ç", "‡§∏‡§ï‡§¶‡•Å", "‡§™‡•à‡§¶‡•Å", "‡§≤‡•à‡§¶‡•Å", "‡§ö‡§æ‡§π‡§ø‡§®‡•ç‡§¶‡•Å", "‡§∏‡§ï‡§¶‡•Å", "‡§™‡•à‡§¶‡•Å"}
PREPOSITIONS: Set[str] = {"‡§Æ‡•á‡§Ç", "‡§™‡§∞", "‡§∏‡•á", "‡§ï‡•ã", "‡§ï‡•á ‡§≤‡§ø‡§è", "‡§§‡•à‡§Ç", "‡§ï‡•à‡§Ç", "‡§Æ‡§æ", "‡§¨‡§ü‡•Ä", "‡§ï‡§®"}
NEGATIONS: Set[str] = {"‡§®‡•à", "‡§ï‡§∏", "‡§®", "‡§®‡•à‡§Ç", "‡§®‡•Ä", "‡§®‡§ø‡§ö"}
CONJUNCTIONS: Set[str] = {"‡§Ö‡§∞", "‡§§‡•à‡§Ç", "‡§ï‡§ø", "‡§ú‡•à‡§Ç", "‡§Ö‡§∞‡•Å", "‡§§‡•à‡§Ç"}
ADVERBS: Set[str] = {"‡§¨‡§°‡§º‡•Ä", "‡§õ‡•ã‡§ü‡•Ä", "‡§ß‡•Ä‡§∞", "‡§§‡•á‡§ú", "‡§Ö‡§ö‡•ç‡§õ‡•Ä", "‡§¨‡§π‡•ã‡§§‡•á", "‡§ß‡•Ä‡§∞‡•Å", "‡§§‡•á‡§ú‡•Ä"}

def process_sentence_with_stanza(sentence: str) -> stanza.Document:
    """
    Processes a sentence using Stanza's Hindi model and returns the parsed doc.
    """
    if not sentence.strip():
        raise ValueError("‚ùå Empty sentence provided")

    if not nlp_hi:
        raise ValueError("‚ùå Stanza model not initialized")

    try:
        doc = nlp_hi(sentence)
        return doc
    except Exception as e:
        raise ValueError(f"‚ùå Error processing sentence with Stanza: {str(e)}")

def categorize_tokens(doc: stanza.Document) -> Tuple[List[str], List[str], List[str], List[str], List[str], List[str], List[str], List[str]]:
    """
    Categorizes tokens into various Gadhwali grammar parts.
    """
    subject, verbs, objects, auxiliaries = [], [], [], []
    modals, preps, negations, others = [], [], [], []

    for sent in doc.sentences:
        for word in sent.words:
            text = word.text.strip()
            upos = word.upos
            dep = word.deprel

            # Handle compound words
            if "-" in text:
                parts = text.split("-")
                for part in parts:
                    if part in HELPING_VERBS:
                        auxiliaries.append(part)
                    elif part in MODALS:
                        modals.append(part)
                    elif part in PREPOSITIONS:
                        preps.append(part)
                    elif part in NEGATIONS:
                        negations.append(part)
                    else:
                        others.append(part)
                continue

            if dep in ("nsubj", "nsubj:pass"):
                subject.append(text)
            elif upos == "VERB":
                verbs.append(text)
            elif upos == "AUX" or text in HELPING_VERBS:
                auxiliaries.append(text)
            elif dep in ("obj", "iobj", "dobj", "pobj"):
                objects.append(text)
            elif text in MODALS:
                modals.append(text)
            elif text in PREPOSITIONS:
                preps.append(text)
            elif text in NEGATIONS:
                negations.append(text)
            else:
                others.append(text)

    return subject, verbs, objects, auxiliaries, modals, preps, negations, others

def correct_gadhwali_structure(sentence: str) -> str:
    """
    Corrects Gadhwali sentence structure using the rule:
    Subject + Object + Negation + Verb + Helping Verb + Modal + Preposition + Others
    """
    if not sentence.strip():
        return sentence

    try:
        doc = process_sentence_with_stanza(sentence)
        subject, verbs, objects, auxiliaries, modals, preps, negations, others = categorize_tokens(doc)

        # Special handling for common Gadhwali patterns
        if not verbs and not auxiliaries and not modals:
            # If no verbs found, return original sentence
            return sentence

        # Handle common Gadhwali patterns
        if "‡§ö" in auxiliaries and not verbs:
            # Handle cases like "‡§Æ‡•à‡§Ç ‡§ñ‡•Å‡§∂ ‡§ö"
            corrected = subject + objects + others + auxiliaries
        else:
            # Standard SOV pattern
            corrected = subject + objects + negations + verbs + auxiliaries + modals + preps + others

        return " ".join(corrected).strip()
    except Exception as e:
        print(f"‚ö†Ô∏è Warning: Could not correct Gadhwali structure: {e}")
        return sentence  # Return original sentence if correction fails

# Test cases
if __name__ == "__main__":
    test_sentences = [
        "‡§Æ‡•à ‡§ñ‡§æ‡§®‡§æ ‡§ñ‡§æ‡§Ç‡§¶‡•Å",                # Basic SOV
        "‡§§‡•Ç ‡§∏‡•ç‡§ï‡•Ç‡§≤ ‡§ú‡•å‡§® ‡§ö‡•å‡§®",             # Modal verb
        "‡§Æ‡•à ‡§ï‡§ø‡§§‡§æ‡§¨ ‡§®‡•à ‡§™‡§¢‡§º‡§®",             # Negation
        "‡§ä ‡§ò‡§∞ ‡§Æ‡•á‡§Ç ‡§õ‡•à",                  # Preposition + helping verb
        "‡§§‡•Å‡§Æ‡§ø ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§£ ‡§ö‡§æ‡§π‡•Ç",           # Modal + helping verb
        "‡§Æ‡•à ‡§¨‡§°‡§º‡•Ä ‡§ß‡•Ä‡§∞ ‡§ö‡§≤‡§£",             # Adverb
        "‡§§‡•Ç ‡§Ö‡§∞ ‡§Æ‡•à ‡§∏‡•ç‡§ï‡•Ç‡§≤ ‡§ú‡•å‡§®",           # Conjunction
        "‡§§‡•Å‡§Ç ‡§ú‡§æ‡§Ç ‡§∏‡§ï‡§¶‡•Å",                 # Modal
        "‡§Æ‡•à‡§Ç ‡§ñ‡•Å‡§∂ ‡§ö",                    # Simple statement
        "‡§§‡•Å‡§Æ ‡§†‡•Ä‡§ï ‡§õ‡§æ",                   # Question form
    ]

    for sentence in test_sentences:
        try:
            corrected = correct_gadhwali_structure(sentence)
            print(f"üëâ Original : {sentence}")
            print(f"‚úÖ Corrected: {corrected}\n")
        except ValueError as e:
            print(f"‚ùå Error: {e}\n")


print("hello i am working")